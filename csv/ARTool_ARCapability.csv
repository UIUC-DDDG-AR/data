Capability,Descripton
ObjectRecognition,"The capability to identify the form and shape of an object and their position in space using a camera and computer vision technique. Object Recognition is able to tell what the object is based on deep learning and machine learning algorithms.
More specifically, Object Recognition can be broken down to three levels: Object detection, recognition and tracking."
Room/SceneRecognition,"The capability to understand the world around you so that AR experiences are more immersive by adding augmented objects to the world in accurate positions. This capability combines recognition of notable scene features with motion sensing data to recognize larger structures than table-size objects, rooms, faces of buildings, courtyards and etc. It works best with predictable lighting conditions."
HandTracking,"The capability to recognize hands’ movements and/or gestures. Hands can be used to interact with menus, models, and the environment. For example, it can be used to practice hands-on activities for education and training, such as surgeons and mechanics. (Current hand tracking is accurate but not from all angles/all situations)"
EyeTracking,"The capability to track where a person’s gaze is directed by using human-facing sensors. Applications include: detecting a person’s presence, attention, and focus, eye-controlled UI, and rendering optimization. Note: many AR hardwares do not have eye-tracking on but one can use add-ons, such as Pupil Core Binocular."
ExtendedTracking,"The capability to keep digital augmentations that are attached to a targeted object, scene, or image to stay in the FOV even when the initial target is no longer in the field of view or cannot be directly tracked for other reasons. Therefore, AR experiences feel more fluid and immersive."
6DoF,"6DoF (6 Degrees of Freedom of movement in 3D space) refers to both translation and rotation about x,y and z axes (yaw, pitch, roll). In addition to the accelerometer and gyroscope, 6DoF requires camera(s) or external sensors in order for it to work accurately. "
3DoF,"3DoF (3 Degrees of Freedom of movement in 3D space) refers to rotation(yaw, pitch,roll) about x,y and z axes. It  lacks the other three movements of  translation. However, there are hardware add-ons to enable a 3DoF equipment to do 6DoF."
MarkerTracking,"The capability to recognize and track specific images through cameras and superimpose virtual content onto them. These images sometimes are referred to fiducial markers (AR markers). Using computer vision techniques of contour detection, feature extraction and pose estimation, the AR hardware processes the data of image position, size and orientation from the markers for building virtual content."
PlaneDetection,"Plane Tracking, or marker-less tracking, uses objects in the image frame instead of an AR marker in addition to the standard computer vision techniques. For example, AKAZE or ORB from OpenCV is used to compare local features and to find matches between video frames. Compared to marker tracking, Plane Tracking requires good lighting, not as robust, and has higher computation cost."
FacialRecognition,"Facial Recognition identifies or verifies a person, which generally works by creating a template of the target’s facial image and comparing the template to preexisted photos of faces. The template is created by use of measurements, distance between eye, width of nose, length of jaw line. Moreover, it can work by extracting landmarks such as a nose or eyes. In general, there are two approaches, geometric (shapes) or photometric (pixels). 3D facial recognition is not affected by lighting. Common applications include photo tagging, security, social media filters, and etc. One note is that for biometrics, it is less accurate than iris or fingerprint recognition."
GPS,"For software, location-based tracking means being able to anchor a virtual object onto the real world by longitude and latitude data. Global Positioning System (GPS) is a satellite-based radionavigation system and  provides geolocation and time information anywhere on or near the Earth where there is an unobstructed line of sight to four or more gps satellites (31 in orbit). The accuracy depends on weather, line of sight to satellites, number of channels on receiver."
DepthSensing,"The capability to  understand which objects are closer than others. Two common approaches. Method 1: Depth sensor uses an infrared projector that measures the time it takes for the infrared light to reflect off objects. Method 2: two camera lenses to compare two images to capture the depth of objects in stereo, like how human eyes do."
PictureTaking,"The capability to take a screenshot of what the user is seeing.
Some devices are able to capture the virtual image along the real for combined AR results.
"
VideoRecording,The capability to record a video and audio of what the user is seeing. Some devices are able to capture the virtual content superimposed on the real world.
Communication_VideoStreaming,The capability to stream what the user is seeing or the camera is pointed to so that multiple users can operate on the shared data in real time.
Communication_Calling,The capability to call or communicate to another user through audio.
Communication_Telepresence,"Telepresence refers to a set of technologies which allow a person to feel as if they were present, to give the appearance of being present, or to have an effect. One approach is to capture a person’s appearance and body movements and present a hologram of them to the other connected device in real time, as if the person is present in another user’s context."
LightEstimation,"The capability to detect the lighting data of the user’s environment. Some AR features need lighting data for better performance and/or user-experiences. For example, it can be used to adjust intensity and colors of the virtual content to be more visible."
Non-native,"Non-native means the AR content can be running on several platforms like mobile phones, computers, and laptops by sharing via a URL web link. Users do not have to download any native apps to their devices."
Computing units compatibility,"A majority of AR glasses require a standalone computing unit to run and process data. The capability of Hardware cross-platform means whether the AR glasses (or other devices) can be run on different computing units, like iphones, android phones, PC and etc."
LightProjection,"Project-based AR directly overlays digital projection onto the physical world, which can create an immersive and shared AR experience. It typically works on projectors with depth cameras. For some, users are able to touch and interact with virtual content."
VoiceRecognition,"The capability to recognize humans’ speeches. Voice recognition is commonly used to perform commands on a device or multiple connected devices so that users don’t have to use a mouse, keyboarch or press any buttons. Use cases include voice dialing, domotic appliance control in smart homes, and etc."
HandController,"A piece of hardware that users can interact with hands to operate a device. This includes touchpads, which support familiar swipes and tap gestures to operate a device. Some AR equipment are using phones as a controller while functioning as a computer unit to the equipment."
Cloud/SpatialAnchor,"By sharing virtual content to the cloud and anchoring it to a shared physical space, multiple users can view and interact the virtual content from different positions simultaneously in real time."
Show2DContent,"Able to visualize 2D contents such as texts, images, and/or videos"
Show3DContent,Able to visualize 3D contents such as 3D models and animations
Body Recognition,"The capability to recognize whether there's a body in the scene/environment. Some are able to do body segmentation by narrowing down body parts to joints and connections. Potential applications include detecting human presence, body and movement tracking, and etc."
Cylinder/conical surface detection and tracking (software),"Able to place AR content onto curved surfaces such as soda cans, in addition to planes, flat markers and images."
Motion Capture,"The process or technique of recording patterns of movement digitally, especially the recording of an actor's movements for the purpose of animating a digital character in a movie or video game. (Definition from Oxford Dictionary)"
people occlusion,"The capability to hide virtual objects behind people or show in front based on real world depth order, which makes AR experience more immersive. This requires the capability to understand the real world environments and objects so virtual objects can interact with people accurately."
Multi-object tracking,Able to track multiple objects.